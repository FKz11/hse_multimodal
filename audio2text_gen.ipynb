{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIg3aW4bwYjs"
      },
      "source": [
        "## Домашнее задание №2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFuXCoI6waaU"
      },
      "source": [
        "### Автор: Сергеев Константин Олегович"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcksD6x4whOm"
      },
      "source": [
        "### Задание"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ailKuL7nx57V"
      },
      "outputs": [],
      "source": [
        "## Добавление аудио входа в модель QWEN 0.5B\n",
        "\n",
        "# - На датасете AudioCaps с использованием предобученного аудио энкодера (HuBERT,\n",
        "# wav2vec2, whisper encoder) обучить адаптер для аудио.\n",
        "# - Саму LLM и энкодер не размораживать.\n",
        "# - Проверить несколько настроек пулинга (векторов на секунду аудио).\n",
        "# - DoD – падение лосса при обучении и примеры генерации описаний аудио на\n",
        "# отложенном сете. Задание считается выполненным, если продемонстрировано,\n",
        "# что модель по мере падения лосса начинает генерировать соответствующие аудио описания.\n",
        "# - В качестве метрики можно использовать BERT-score между\n",
        "# сгенерированными и истинными описаниями\n",
        "# - Стоит обратить внимание на возможность лика в данных при формировании\n",
        "# отложенной выборки (очень похожие звуки или одни и теже дорожки с разным описанием)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SWfMLU1yVuw"
      },
      "source": [
        "### Импортируем библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "P5VtRguC7QIB"
      },
      "outputs": [],
      "source": [
        "#!pip -qq install bert_score\n",
        "#!pip install --upgrade transformers\n",
        "#!pip uninstall flash-attn -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBDJVS5KvBR_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from transformers import Wav2Vec2Model, Wav2Vec2Processor, AutoModelForCausalLM, AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from bert_score import score as bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWpvSzr3oUus"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg2Cg9JZ7QIC"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSj94ISfytn3"
      },
      "source": [
        "### Загрузка предобученного аудио энкодера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vudY6XMPIn_c",
        "outputId": "65f8d7fa-144c-4350-d9bc-ec7ed38b5335"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/konsergeev/venv/lib/python3.10/site-packages/transformers/configuration_utils.py:311: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "audio_encoder = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\").to(device)\n",
        "audio_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
        "\n",
        "for param in audio_encoder.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9FZfPHCy2IV"
      },
      "source": [
        "### Загрузка модели QWEN 0.5B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvjPSOtHo7-4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "llm = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "for param in llm.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTeBAxTUzkRY"
      },
      "source": [
        "### Формируем датасет из AudioCaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTfz1XnVzoBh"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GTzycUczrBS"
      },
      "outputs": [],
      "source": [
        "#!unzip -qq \"/content/gdrive/MyDrive/Colab Notebooks/audiocaps.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM4r6piDztLG",
        "outputId": "a7804cbd-0a90-423f-f6b1-7f240130ccbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████| 49490/49490 [04:51<00:00, 169.61it/s]\n",
            "100%|███████████████████████████████████| 49490/49490 [00:10<00:00, 4685.08it/s]\n",
            "100%|████████████████████████████████████████| 495/495 [00:02<00:00, 177.38it/s]\n",
            "100%|███████████████████████████████████████| 495/495 [00:00<00:00, 4403.83it/s]\n",
            "100%|████████████████████████████████████████| 963/963 [00:05<00:00, 177.39it/s]\n",
            "100%|███████████████████████████████████████| 963/963 [00:00<00:00, 4344.71it/s]\n"
          ]
        }
      ],
      "source": [
        "class AudioCapsDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        audios = df['audio'].values\n",
        "        self.audio_inputs = []\n",
        "        for audio_path in tqdm(audios):\n",
        "            waveform, sample_rate = torchaudio.load(data_folder + audio_path)\n",
        "            input = audio_processor(waveform[0], sampling_rate=sample_rate,\n",
        "                                    return_tensors=\"pt\", padding='max_length',\n",
        "                                    truncation=True, max_length=160000)\n",
        "            self.audio_inputs.append(input['input_values'][0])\n",
        "        self.descriptions = df['text'].values\n",
        "        self.labels = []\n",
        "        for description in tqdm(self.descriptions):\n",
        "            tokenized = tokenizer(tokenizer.pad_token + description, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\")\n",
        "            tokenized_ids = tokenized['input_ids'][0]\n",
        "            self.labels.append(tokenized_ids)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.descriptions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.audio_inputs[idx], self.descriptions[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "data_folder = '/mnt/sdb/konsergeev/hse/'\n",
        "df_train = pd.read_csv(data_folder + 'audiocaps/audiocaps_train.tsv', sep='\\t')\n",
        "df_val = pd.read_csv(data_folder + 'audiocaps/audiocaps_val_new.tsv', sep='\\t')\n",
        "df_test = pd.read_csv(data_folder + 'audiocaps/audiocaps_test_new.tsv', sep='\\t')\n",
        "\n",
        "train_dataset = AudioCapsDataset(df_train)\n",
        "val_dataset = AudioCapsDataset(df_val)\n",
        "test_dataset = AudioCapsDataset(df_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agwu3jVILqrA"
      },
      "source": [
        "### Определение аудио адаптера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXPl76oe3uyb",
        "outputId": "5c5f75ab-3a72-46ce-c296-e45f8d2595a2",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 125, 896])\n",
            "Количество векторов на 10 сек аудио: 125\n"
          ]
        }
      ],
      "source": [
        "class AudioAdapter(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size=3, stride=2, padding=1):\n",
        "        super(AudioAdapter, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=output_dim,\n",
        "                               kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.conv1(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "adapter = AudioAdapter(input_dim=audio_encoder.config.hidden_size,\n",
        "                       output_dim=llm.config.hidden_size,\n",
        "                       #kernel_size=3, stride=2, padding=1  # 250 векторов\n",
        "                       kernel_size=7, stride=4, padding=3  # 125 векторов\n",
        "                       #kernel_size=15, stride=8, padding=7  # 63 вектора\n",
        "                       #kernel_size=31, stride=16, padding=15  # 32 вектора\n",
        "                       #kernel_size=61, stride=31, padding=30  # 17 векторов\n",
        "                       #kernel_size=121, stride=61, padding=60  # 9 векторов\n",
        "                      ).to(device)\n",
        "\n",
        "# тест\n",
        "test_input = test_dataset[0][0].to(device)\n",
        "test_audio_features = audio_encoder(test_input.unsqueeze(0)).last_hidden_state\n",
        "adapted_features = adapter(test_audio_features)\n",
        "print(adapted_features.shape)\n",
        "print(f'Количество векторов на 10 сек аудио: {adapted_features.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxsPeJIyUDCI"
      },
      "source": [
        "### Обучение аудио адаптера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlzH-p6Upe6F",
        "scrolled": true,
        "outputId": "002d7dcb-00a2-41b3-b8f5-d1c363ed8950"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 3094/3094 [34:35<00:00,  1.49it/s]\n",
            "  0%|                                                    | 0/62 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "100%|███████████████████████████████████████████| 62/62 [02:35<00:00,  2.52s/it]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "Train Loss: 3.4458\n",
            "Val Loss: 3.0403\n",
            "Average Val BERTScore: 0.8359\n",
            "Generated Example 1: ， a dog barks and then the dog is patted on the head. The dog barks again and then it starts to walk around in circles. A man speaking with a voice that sounds like someone is talking but not very clearly. There are no other noises present. The dog barks several times and then it\n",
            "Reference Example 1: Pigeons vocalize and a child speaks\n",
            "Generated Example 2: ， a man speaks and then a woman speaks, followed by a dog barking. A crowd of people are cheering and clapping in response to the speaker's speech. The crowd is cheering and clapping loudly as well. A man speaking with a dog barking in the background. A crowd cheers and claps as\n",
            "Reference Example 2: A dog barks and growls while a man speaks then the dog stops barking and then people begin talking\n",
            "Generated Example 3: ， a dog barks and sniffs. A woman speaking with a baby crying. The sound of a dog barking is followed by the sound of a man talking to a child. A dog barks and sniffs, then a woman speaks to a child. A dog barks and sniffs again. A woman\n",
            "Reference Example 3: Loud laugh ting and mumbling with s person laughing faintly and briefly in the distance\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 3094/3094 [34:33<00:00,  1.49it/s]\n",
            "100%|███████████████████████████████████████████| 62/62 [02:36<00:00,  2.52s/it]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/3\n",
            "Train Loss: 3.0604\n",
            "Val Loss: 2.9101\n",
            "Average Val BERTScore: 0.8337\n",
            "Generated Example 1: ， then a person speaks and the sound of a dog barking. The dog barks, then a man speaks while a dog barks in response to the man’s speech. A bird chirps and a dog barks. Then a woman speaks and a dog barks. The dog barks again, then a\n",
            "Reference Example 1: Pigeons vocalize and a child speaks\n",
            "Generated Example 2: ， then a man speaks and a woman responds. A crowd of people speak in the background, but no one is speaking loudly. The audience applauds as a man speaks to an audience. A man speaks to a group of people, followed by applause. A man speaks to a group of people, followed by applause.\n",
            "Reference Example 2: A dog barks and growls while a man speaks then the dog stops barking and then people begin talking\n",
            "Generated Example 3:  and a dog barks and a person speaks in the background. A woman speaking with a dog nearby laughs and a man speaking nearby laughs as well. The sound of a dog barking is repeated several times, followed by a woman laughing and a man laughing. There are no other sounds present except for the dog barking\n",
            "Reference Example 3: Loud laugh ting and mumbling with s person laughing faintly and briefly in the distance\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 3094/3094 [34:34<00:00,  1.49it/s]\n",
            "100%|███████████████████████████████████████████| 62/62 [02:36<00:00,  2.53s/it]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/3\n",
            "Train Loss: 2.9652\n",
            "Val Loss: 2.8734\n",
            "Average Val BERTScore: 0.8370\n",
            "Generated Example 1: ， a person speaks and then the door opens and closes, followed by a bird chirping. The door is closed for a moment, then it is opened again, and the door is closed again. A person speaking in the background, then the door is opened again, and the door is closed again. Birds are chir\n",
            "Reference Example 1: Pigeons vocalize and a child speaks\n",
            "Generated Example 2: ， crowd cheering and applause, woman speaking to audience in background, adult male voice followed by a woman speaking to audience in background, crowd cheering and applause, adult female voice speaks to audience in background, crowd cheering and applause, adult male voice speaks to audience in background, crowd cheering and applause, adult female voice speaks to\n",
            "Reference Example 2: A dog barks and growls while a man speaks then the dog stops barking and then people begin talking\n",
            "Generated Example 3:  then a woman speaks and laughs, followed by another woman speaking and laughing as well. A dog barks and a man speaks in the background while a woman laughs and talks to a child nearby, then a woman speaks again and laughs, then a dog barks and a man speaks again and laughs, then a woman speaks\n",
            "Reference Example 3: Loud laugh ting and mumbling with s person laughing faintly and briefly in the distance\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Определение функции потерь и оптимизатора\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "optimizer = optim.Adam(adapter.parameters(), lr=1e-4)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "# Обучение\n",
        "adapter.train()\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    val_loss = 0\n",
        "\n",
        "    for audio_inputs, descriptions, labels in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        audio_inputs = audio_inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Пропуск через аудио энкодер\n",
        "        audio_features = audio_encoder(audio_inputs).last_hidden_state\n",
        "\n",
        "        # Пропуск через аудио адаптер\n",
        "        adapted_features = adapter(audio_features)\n",
        "\n",
        "        # Получение эмбедингов токенов описания\n",
        "        text_features = llm._modules['model'].embed_tokens(labels)\n",
        "\n",
        "        # Итоговая входная последовательность эмбедингов в LLM\n",
        "        input_features = torch.cat([adapted_features, text_features], 1)\n",
        "\n",
        "        # Пропуск через LLM\n",
        "        outputs = llm(inputs_embeds=input_features)\n",
        "\n",
        "        # Вычисление ошибки\n",
        "        target_logints = outputs.logits.permute(0, 2, 1)[:, :, adapted_features.shape[1]:-1]\n",
        "        target_labels = labels[:, 1:]\n",
        "        loss = criterion(target_logints, target_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Валидация\n",
        "    adapter.eval()\n",
        "    all_predictions = []\n",
        "    all_references = []\n",
        "    with torch.no_grad():\n",
        "        for audio_inputs, descriptions, labels in tqdm(val_loader):\n",
        "            audio_inputs = audio_inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Пропуск через аудио энкодер\n",
        "            audio_features = audio_encoder(audio_inputs).last_hidden_state\n",
        "\n",
        "            # Пропуск через аудио адаптер\n",
        "            adapted_features = adapter(audio_features)\n",
        "\n",
        "            # Получение эмбедингов токенов описания\n",
        "            text_features = llm._modules['model'].embed_tokens(labels)\n",
        "\n",
        "            # Итоговая входная последовательность эмбедингов в LLM\n",
        "            input_features = torch.cat([adapted_features, text_features], 1)\n",
        "\n",
        "            # Пропуск через LLM\n",
        "            outputs = llm(inputs_embeds=input_features)\n",
        "\n",
        "            # Вычисление ошибки\n",
        "            target_logints = outputs.logits.permute(0, 2, 1)[:, :, adapted_features.shape[1]:-1]\n",
        "            target_labels = labels[:, 1:]\n",
        "            loss = criterion(target_logints, target_labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Генерация\n",
        "            generated_ids = llm.generate(inputs_embeds=adapted_features, max_new_tokens=64, temperature=0.01)\n",
        "            generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "            all_predictions.extend(generated_texts)\n",
        "            all_references.extend(descriptions)\n",
        "\n",
        "    # Подсчёт среднего лосса и BERTScore\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    P, R, F1 = bert_score(all_predictions, all_references, lang='en')\n",
        "    avg_bert_score = F1.mean().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"Average Val BERTScore: {avg_bert_score:.4f}\")\n",
        "    for i in range(3):\n",
        "        print(f\"Generated Example {i+1}: {generated_texts[i]}\")\n",
        "        print(f\"Reference Example {i+1}: {descriptions[i]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2whzyLC7QIE"
      },
      "source": [
        "### Тесты количества подаваемых векторов в LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuLtYpoR7QIE"
      },
      "outputs": [],
      "source": [
        "def eval_test():\n",
        "    adapter.eval()\n",
        "    test_loss = 0\n",
        "    all_predictions = []\n",
        "    all_references = []\n",
        "    with torch.no_grad():\n",
        "        for audio_inputs, descriptions, labels in tqdm(test_loader):\n",
        "            audio_inputs = audio_inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Пропуск через аудио энкодер\n",
        "            audio_features = audio_encoder(audio_inputs).last_hidden_state\n",
        "\n",
        "            # Пропуск через аудио адаптер\n",
        "            adapted_features = adapter(audio_features)\n",
        "\n",
        "            # Получение эмбедингов токенов описания\n",
        "            text_features = llm._modules['model'].embed_tokens(labels)\n",
        "\n",
        "            # Итоговая входная последовательность эмбедингов в LLM\n",
        "            input_features = torch.cat([adapted_features, text_features], 1)\n",
        "\n",
        "            # Пропуск через LLM\n",
        "            outputs = llm(inputs_embeds=input_features)\n",
        "\n",
        "            # Вычисление ошибки\n",
        "            target_logints = outputs.logits.permute(0, 2, 1)[:, :, adapted_features.shape[1]:-1]\n",
        "            target_labels = labels[:, 1:]\n",
        "            loss = criterion(target_logints, target_labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Генерация\n",
        "            generated_ids = llm.generate(inputs_embeds=adapted_features, max_new_tokens=64, temperature=0.01)\n",
        "            generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "            all_predictions.extend(generated_texts)\n",
        "            all_references.extend(descriptions)\n",
        "\n",
        "    # Подсчёт среднего лосса и BERTScore\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    P, R, F1 = bert_score(all_predictions, all_references, lang='en')\n",
        "    avg_bert_score = F1.mean().item()\n",
        "\n",
        "    print(f\"Test Loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"Average Test BERTScore: {avg_bert_score:.4f}\")\n",
        "    for i in range(3):\n",
        "        print(f\"Generated Example {i+1}: {generated_texts[i]}\")\n",
        "        print(f\"Reference Example {i+1}: {descriptions[i]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ro1M8Z7QIE"
      },
      "source": [
        "#### 250 векторов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_KPt5a_z9Q8",
        "scrolled": true,
        "outputId": "ef60a65d-b60a-4c99-fa29-1a45bbd10d16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████| 121/121 [05:15<00:00,  2.61s/it]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.8656\n",
            "Average Test BERTScore: 0.8252\n",
            "Generated Example 1:  A car engine is running and a person speaking in the background with a loud noise of wind blowing through the windows as well as a ticking sound of an alarm clock. The engine makes a clicking sound when it starts up, then stops and repeats itself every few seconds. The engine makes a whirring sound as it spins\n",
            "Reference Example 1: An engine idling with light wind\n",
            "Generated Example 2:  \"A man speaking and a bird chirping\" is said with the sound of birds flying by in the background\n",
            "\n",
            "### 10.2: Bird chirping, man talking, and bird chirping\n",
            "\n",
            "The sound of birds chirping can be heard as a man speaks nearby. The bird chirps several times before\n",
            "Reference Example 2: Man talking and a tapping clicking\n",
            "Generated Example 3: ulpture of a dog barking and a cat meowing followed by a woman speaking in a low voice while the door opens and closes several times, then the door closes again and the sound stops abruptly with a loud bang and the door is closed again. The dog barks and the cat meows as well. The\n",
            "Reference Example 3: People are speaking, and a goat bleats\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
          ]
        }
      ],
      "source": [
        "eval_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJgs9O4e7QIF"
      },
      "source": [
        "#### 125 векторов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69JDDxla7QIF",
        "outputId": "023af51b-3b17-4269-8ed5-07fbccd5757d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████| 121/121 [05:02<00:00,  2.50s/it]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.9880\n",
            "Average Test BERTScore: 0.8470\n",
            "Generated Example 1:  a train moving and then stopping with a loud engine sound and a car door closing.\n",
            "A passenger is sitting in the driver's seat, driving the vehicle. The engine sounds are low and steady as the car moves forward. A person speaking to the passenger about something they are talking about while the car drives by. The speaker\n",
            "Reference Example 1: An engine idling with light wind\n",
            "Generated Example 2: , a man speaks and then a bird chirps, then the wind blows, and then a woman talks. A man speaking followed by birds chirping in the background. Then a man speaks again and a bird chirp is heard. The wind blows and a woman speaks. A man speaks and then birds chirp in\n",
            "Reference Example 2: Man talking and a tapping clicking\n",
            "Generated Example 3: , a man speaking and a woman talking with a dog barking followed by a cat meowing. A child is laughing while a man speaks to the camera. A car horn sounds as a person laughs. A baby cries in the background. A woman talks to the camera. A dog barks and then a cat me\n",
            "Reference Example 3: People are speaking, and a goat bleats\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_Z3wNq37QIF"
      },
      "source": [
        "#### 63 вектора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCLReeeQ7QIF",
        "outputId": "f24e54b6-c721-4ec1-8ce0-202cb6ada58b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████| 121/121 [04:59<00:00,  2.48s/it]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.8290\n",
            "Average Test BERTScore: 0.8431\n",
            "Generated Example 1:  2-3 times a minute with water splashing and a bird chirping in the background as it moves around slightly more than once every second. A small engine is running, then stops for a moment before starting again. The sound of a car engine is heard. Water splashes and some birds are chirping.\n",
            "Reference Example 1: An engine idling with light wind\n",
            "Generated Example 2:  of a horse’s hoofbeats and a man speaking in the background then more speech followed by a horse hooves clattering as water splashes nearby with a horse’s hooves clicking and a horse’s hooves scraping on the ground in the background then a man speaks while a horse's hooves click and scrape again\n",
            "Reference Example 2: Man talking and a tapping clicking\n",
            "Generated Example 3:  and a baby cries with a woman speaking in the background while a child is crying and a man speaks to them in the background then another child cries and a woman speaks again before the children cry again and a man speaks once more before the children cry again and a woman speaks again before the children cry again and a man speaks\n",
            "Reference Example 3: People are speaking, and a goat bleats\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b_h7d0D7QIF"
      },
      "source": [
        "#### 32 вектора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vNAeFpd7QIF",
        "outputId": "cade3830-2003-4245-d98d-b6bd5b8846d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████| 121/121 [04:56<00:00,  2.45s/it]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.8103\n",
            "Average Test BERTScore: 0.8371\n",
            "Generated Example 1: Coroutine of a man speaking and then the sound of water flowing in the background with a distant bird chirping nearby. A person speaks loudly, but there is no wind or noise in the background. The water is moving slowly as well. Birds are singing. There is a loud clapping sound. Then the water stops and\n",
            "Reference Example 1: An engine idling with light wind\n",
            "Generated Example 2: 间 a man speaking and then some noise followed by water flowing in the background as he speaks again. The water is running fast, but it's not very loud. A woman talks nearby.\n",
            "A man speaking with his voice rising higher as he speaks.\n",
            "The water is bubbling and splashing around.\n",
            "A dog barks\n",
            "Reference Example 2: Man talking and a tapping clicking\n",
            "Generated Example 3:   A child is crying and a woman speaks to the child then another child cries and a man speaks to the child. Then another child cries and a woman speaks to the child. Another child cries and a man speaks to the child. The children are all crying. A woman speaking to the children. A dog barks\n",
            "Reference Example 3: People are speaking, and a goat bleats\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPvKfhxX7QIF"
      },
      "source": [
        "#### 17 векторов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cm7RwqP7QIF",
        "outputId": "6ec6273c-2327-4348-9a13-a5d3ee5b5e3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████| 121/121 [04:54<00:00,  2.43s/it]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.7928\n",
            "Average Test BERTScore: 0.8246\n",
            "Generated Example 1: id driving with a car engine running and a man speaking in the background as a motorcycle passes by on the road. The man is talking about something nearby, but it's hard to hear him clearly because of the noise from the vehicle and the wind blowing around them. A woman is speaking to someone else nearby, but she\n",
            "Reference Example 1: An engine idling with light wind\n",
            "Generated Example 2: 泉水 flowing with a man speaking and birds chirping in the background as water splashes nearby, followed by a woman talking while she sings a song into a microphone. The sound is soft but there are some clinking sounds of metal objects being removed from a sink faucet.</figcaption> <figure class=\"image-object image-object\n",
            "Reference Example 2: Man talking and a tapping clicking\n",
            "Generated Example 3: id dogs barking and a woman speaking in the background followed by a man laughing and talking in the background, then a dog barks again and a woman speaks in the background followed by a man laughing and talking in the background, then another dog barks and a woman speaks in the background followed by a man laughing and\n",
            "Reference Example 3: People are speaking, and a goat bleats\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i_Ipx237QIF"
      },
      "source": [
        "#### 9 векторов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VHPvuPl7QIF",
        "outputId": "5da96ed0-7c0c-46bc-997f-d9519c5f4a34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████| 121/121 [04:53<00:00,  2.43s/it]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.8062\n",
            "Average Test BERTScore: 0.7969\n",
            "Generated Example 1: --}}\n",
            "A vehicle engine is running and a man speaks in the background\n",
            "An ambulance chimes its horn as it passes by\n",
            "The crowd cheers loudly as people walk around\n",
            "People are talking about something nearby\n",
            "A car is moving slowly on the road\n",
            "A police officer is speaking to someone nearby\n",
            "A group of people are\n",
            "Reference Example 1: An engine idling with light wind\n",
            "Generated Example 2: 川话的说话声伴随着轻微风声和雨滴声，风吹过窗帘时有轻微的响声，人说话声在空气中轻柔地飘动，偶尔有风吹过窗帘的声音，人说话声在空气中轻柔地飘动，偶尔有风吹过窗帘的声音，人说话声在\n",
            "Reference Example 2: Man talking and a tapping clicking\n",
            "Generated Example 3: 川话与人说话的重复声，人说话的声音由轻到重逐渐变高，人说话声音由低到高，人说话的人在说话，人说话的声音由轻到重逐渐变高，人说话的人在说话，人说话的人在说话，人说话的人在说话，人\n",
            "Reference Example 3: People are speaking, and a goat bleats\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0xsYb8h7QIF"
      },
      "source": [
        "### Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i15V-sYo7QIF"
      },
      "source": [
        "- Задача казалась гораздо легче на 1-ый взгляд, я её сильно недооценил, ведь когда дошло до реализации, оказалось не просто придумать, как всё таки передавать на вход LLM эмединги, а обучаться по токенам\n",
        "- Видно, что система обучается с количеством эпох, Loss становится меньше, BertScore больше, а генерации лучше\n",
        "- Результаты не идеальные, но и LLM всего 0.5B, которую мы при этом не размораживали\n",
        "- В целом генерация получается тематически похожей на референс, что видно по неплохому BertScore\n",
        "- Генерации получаются заметно длинне чем референс\n",
        "- Иногда генерации получаются такие, что модель просто перечесляет все возможные описания звуков, такой локальный оптимум)\n",
        "- На ранних этапах обучения, генерировались рандомные символы где не было человеской речи, это самые сложные примеры. А где была речь, уже генерировался привычный текст\n",
        "- После тестов разного количества входных векторов, оказалось, что лучшие результаты у 125 векторов на входе, что достигается при kernel_size=7, stride=4 и padding=3 у свёрточного слоя. Но важное уточнения, что помимо количество векторов на входе, так же менялось и количество параметров у адаптера\n",
        "- В целом считаю проделанную работу и результат успешным"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Что можно сделать ещё"
      ],
      "metadata": {
        "id": "c6eSBr6R77GQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Попробовать разморозить LLM\n",
        "- Подобрать входной промт\n",
        "- Протестить другую архитектуру адаптера, например несколько свёрток подряд"
      ],
      "metadata": {
        "id": "Fw9UfGbI7-tS"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}